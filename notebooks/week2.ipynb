{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2: Mean Time Spent in Transient States and Gambler's ruin problem\n",
    "\n",
    "* Studying the Mean TIme in Transient States (for Practice Problem) \n",
    "* Simulating and analyzing the MC associated with the Gambler's Ruin Problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Time in Transient States\n",
    "\n",
    "We saw in class that the states of a Markov chain are either recurrent (Probability of return =1) or transient. We will see here how to compute the mean time spend in a transient state.\n",
    "\n",
    "We consider here a finite state Markov Chain with a set of transient states numbered as $T= \\left\\{ 1, 2, \\ldots, t \\right\\} $.\n",
    "\n",
    "Let us define the transition matrix of transient states $\\mathbf{P}_T$, such that $(\\mathbf{P}_T)_{ij} = p_{ij} = P(X_1 =j \\ | \\ X_0=i)$ ($\\mathbf{P}_T$ is a sub-matrix of the original full transition matrix of the Markov Chain). \n",
    "\n",
    "We also introduce the matrix $\\mathbf{S}$ of size $t$, such that $(\\mathbf{S})_{ij} = s_{ij}$ is the expected number of times where the Markov Chain is in state $j$, given it starts in state $i$. By conditioning on the initial transition, one can show (do it as an exercise) that \n",
    "\n",
    "\\begin{equation}\n",
    "s_{ij} = \\delta_{ij} + \\sum_{k=1}^t p_{ik} s_{kj},\n",
    "\\end{equation}\n",
    "where $\\delta_{ij} = 1$ if $i=j$ and 0 else. In matrix notation one can be write this equation as\n",
    "\\begin{equation}\n",
    "\\mathbf{S} = \\mathbf{I} + \\mathbf{P}_T \\mathbf{S},\n",
    "\\end{equation} \n",
    "so \n",
    "\\begin{equation}\n",
    "\\mathbf{S} = (\\mathbf{I} - \\mathbf{P}_T)^{-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application\n",
    "\n",
    "For a given matrix $\\mathbf{P}_T$, the following block computes $\\mathbf{S}$ (we can use it to solve practice problems, or find the probability of return $f_i$ associated with transient states (cf. properties of transience seen in class and section 4.6 in Ross textbook)). We will see next how we can apply that to the so-called Gambler's ruin problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify your PT\n",
    "PT = XXX #example: np.matrix([[0,1/4],[1/3,0]])\n",
    "\n",
    "S = np.linalg.inv(np.identity(PT.shape[0]) - PT)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Gambler's Ruin Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now present a classical problem of Markov chain with transient and recurrent states. Consider a gambler who at each play of the game has probability $p$ of winning one dollar and probability $q=1-p$ of losing one dollar. The game stops if the gambler gets ruined or if their fortune gets to $N$.\n",
    "\n",
    "By modifying the 1D Random Walk (cf. week 1), we can simulate a trajectory of the Markov Chain associated with the Gambler's Ruin Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "# starting with $25\n",
    "x.append(25)\n",
    "# amount of money of the bank\n",
    "N = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability of winning a bet:\n",
    "p = 0.5\n",
    "\n",
    "while 0 < x[-1] < N:\n",
    "    if np.random.rand() <= p:\n",
    "        # winning $1 bet\n",
    "        x.append(x[-1] + 1) \n",
    "    else:\n",
    "        # losing $1 bet\n",
    "        x.append(x[-1] - 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the outcome of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.set_xlabel(\"t [bets]\")\n",
    "ax.set_ylabel(\"amount of money [$]\")\n",
    "ax.plot(x, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By simulating the process many times, play with the parameters of the problem and see what's the probability of ruin (this can be found analytically, cf. Homework 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify any of these parameters to see what happens\n",
    "nrealizations = 1000\n",
    "p = 0.50      # P(winning a bet)\n",
    "N = 50      # money of bank\n",
    "x0 = 40      # initial state\n",
    "\n",
    "realizations = []\n",
    "\n",
    "for r in range(nrealizations):\n",
    "    x = [x0]\n",
    "    while 0 < x[-1] < N:\n",
    "        if np.random.rand() <= p: # (note that Lebesgue_measure(np.random.rand() = p) = 0)\n",
    "            # winning $1 bet\n",
    "            x.append(x[-1] + 1) \n",
    "        else:\n",
    "            # losing $1 bet\n",
    "            x.append(x[-1] - 1)\n",
    "    realizations.append(x)\n",
    "\n",
    "# count the times of ruin\n",
    "nruins = 0\n",
    "for x in realizations:\n",
    "    if x[-1] == 0:\n",
    "        nruins += 1\n",
    "        \n",
    "print(\"Probability of ruin is approximately\", nruins / nrealizations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now study the transient states (cf. lecture) {1, ..., N-1} and the probability of revisiting a state. For a state i, the following block allows to extract, from running M simulations over n steps with initial state i, what is the fraction of trajectories such that i was revisited. We set n large (1000), so the results of the simulations approximate the probability of return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify any of these parameters again to see what happens\n",
    "M = 1000      # number of simulations\n",
    "n = 100       # number of steps\n",
    "p = 0.49      # P(winning a bet)\n",
    "N = 50      # money of bank\n",
    "i = 25       # initial state\n",
    "\n",
    "revisited = np.zeros(M)\n",
    "for r in range(M):\n",
    "    x = [i]\n",
    "    step = 1\n",
    "    while 0 < x[-1] < N and step <= n and revisited[r] != 1:\n",
    "        if np.random.rand() <= p: \n",
    "            # winning $1 bet\n",
    "            x.append(x[-1] + 1) \n",
    "        else:\n",
    "            # losing $1 bet\n",
    "            x.append(x[-1] - 1)\n",
    "        if x[-1] == i:\n",
    "            revisited[r] = 1\n",
    "        step += 1\n",
    "            \n",
    "print(\"Probability of revisiting until nth step is approximately\", np.sum(revisited) / M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also study the average number of times that a trajectory visited state i. The following block allows to extract this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify any of these parameters again to see what happens\n",
    "M = 1000      # number of simulations\n",
    "n = 1000       # number of steps\n",
    "p = 0.49      # P(winning a bet)\n",
    "N = 50      # money of bank\n",
    "i = 25      # initial state\n",
    "\n",
    "visited = np.ones(M)\n",
    "for r in range(M):\n",
    "    x = [i]\n",
    "    step = 1\n",
    "    while 0 < x[-1] < N and step <= n:\n",
    "        if np.random.rand() <= p:\n",
    "            # winning $1 bet\n",
    "            x.append(x[-1] + 1) \n",
    "        else:\n",
    "            # losing $1 bet\n",
    "            x.append(x[-1] - 1)\n",
    "        if x[-1] == i:\n",
    "            visited[r] += 1\n",
    "        step += 1\n",
    "\n",
    "print(\"Mean number of visiting i =\", i, \"is\", np.sum(visited) / M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By experimenting with this multiple times, let's compare the results for different possible values of p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying p\n",
    "p_array = np.linspace(0.02, 0.98, num=50)\n",
    "\n",
    "M = 1000      # number of simulations\n",
    "n = 1000       # number of steps\n",
    "N = 50      # money of bank\n",
    "i = 25       # initial state\n",
    "\n",
    "prob_revis = np.zeros(len(p_array))\n",
    "mean_nvisit = np.zeros(len(p_array))\n",
    "for idx, p in enumerate(p_array):\n",
    "    visited = np.ones(M)\n",
    "    for r in range(M):\n",
    "        x = [i]\n",
    "        step = 1\n",
    "        while 0 < x[-1] < N and step <= n:\n",
    "            if np.random.rand() <= p:\n",
    "                # winning $1 bet\n",
    "                x.append(x[-1] + 1) \n",
    "            else:\n",
    "                # losing $1 bet\n",
    "                x.append(x[-1] - 1)\n",
    "            if x[-1] == i:\n",
    "                visited[r] += 1\n",
    "            step += 1\n",
    "    prob_revis[idx] = len(np.where(visited > 1)[0]) / M\n",
    "    mean_nvisit[idx] = np.sum(visited) / M\n",
    "\n",
    "fig1, ax1 = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax1.set_xlabel(\"Prob. of revisiting until nth step\")\n",
    "ax1.set_ylabel(\"mean number of visit\")\n",
    "ax1.plot(prob_revis, mean_nvisit, lw=0, marker=\"o\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These simulations suggest these two quantities are related. Recall the properties of recurrent and transient states seen in class to see exactly how!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
