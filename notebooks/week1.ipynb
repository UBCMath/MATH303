{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 1: Discrete time Markov chain\n",
    "\n",
    "In this notebook, we provide some code to:\n",
    "\n",
    "* Simulate the symmetric 1D random walk seen in class\n",
    "* Simulate a Markov chain from its transition matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Python libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Symmetric Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 1000 #number of steps to simulate\n",
    "x = np.zeros(nsteps)\n",
    "x[0] = 0 #initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(nsteps - 1):\n",
    "    if np.random.rand() <= 0.5:\n",
    "        x[t + 1] = x[t] + 1 \n",
    "    else:\n",
    "        x[t + 1] = x[t] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the outcome of the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.plot(x, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate multiple realizations of the walk we just need to run the simulation above multiple times and store the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize each realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrealizations = 10 #number of realizations to simulate\n",
    "\n",
    "x = np.zeros((nsteps, nrealizations))\n",
    "x[0] = np.zeros(nrealizations) #initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate each realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(nrealizations):\n",
    "    for t in range(nsteps - 1):\n",
    "        if np.random.rand() <= 0.5:\n",
    "            x[t + 1, r] = x[t, r] + 1 \n",
    "        else:\n",
    "            x[t + 1, r] = x[t, r] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting each realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for r in range(nrealizations):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax.plot(x[:, r], lw=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Simulating a Markov chain using the transition matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class allows to define a Markov Chain from a transition matrix and its states, and simulate the chain (from https://github.com/PacktPublishing/Hands-On-Markov-Models-with-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MarkovChain(object):\n",
    "    def __init__(self, transition_matrix, states):\n",
    "        \"\"\"\n",
    "        Initialize the MarkovChain instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        transition_matrix: 2-D array\n",
    "            A 2-D array representing the probabilities of change of \n",
    "            state in the Markov Chain.\n",
    " \n",
    "        states: 1-D array \n",
    "            An array representing the states of the Markov Chain. It\n",
    "            needs to be in the same order as transition_matrix.\n",
    "        \"\"\"\n",
    "        self.transition_matrix = np.atleast_2d(transition_matrix)\n",
    "        self.states = states\n",
    "        self.index_dict = {self.states[index]: index for index in \n",
    "                           range(len(self.states))}\n",
    "        self.state_dict = {index: self.states[index] for index in\n",
    "                           range(len(self.states))}\n",
    " \n",
    "    def next_state(self, current_state):\n",
    "        \"\"\"\n",
    "        Returns the state of the random variable at the next time \n",
    "        instance.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The current state of the system.\n",
    "        \"\"\"\n",
    "        return np.random.choice(\n",
    "         self.states, \n",
    "         p=self.transition_matrix[self.index_dict[current_state], :]\n",
    "        )\n",
    " \n",
    "    def generate_states(self, current_state, no=10):\n",
    "        \"\"\"\n",
    "        Generates the next states of the system.\n",
    " \n",
    "        Parameters\n",
    "        ----------\n",
    "        current_state: str\n",
    "            The state of the current random variable.\n",
    " \n",
    "        no: int\n",
    "            The number of future states to generate.\n",
    "        \"\"\"\n",
    "        future_states = []\n",
    "        for i in range(no):\n",
    "            next_state = self.next_state(current_state)\n",
    "            future_states.append(next_state)\n",
    "            current_state = next_state\n",
    "        return future_states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block allows to input a transition matrix, initialize the Markov chain and simulate a realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_matrix = [[0.5, 0.5], [0.5,  0.5]]# Input your transition matrix here\n",
    "example_chain = MarkovChain(transition_matrix=transition_matrix, states=['0', '1']) # Name your states here\n",
    "simulation= example_chain.generate_states(current_state='0', no=100) #Simulate the chain (specify the number of states here)\n",
    "arr = np.array(simulation)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "ax.plot(arr, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate multiple realizations of the chain we defined above, we simply call the `generate_states()` method multiple times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize an array for storing all of our simulation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrealizations = 10\n",
    "nsteps = 100\n",
    "\n",
    "arr = np.zeros((nsteps, nrealizations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `generate_states()` once for each realization and store the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(nrealizations):\n",
    "    simulation = example_chain.generate_states(current_state='0', no=nsteps)\n",
    "    arr[:, r] = np.array(simulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the realizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(nrealizations):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "    ax.plot(arr[:, r], lw=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the empirical distribution over the states at some time step `N` using the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empirical_dist(states, transition_matrix, initial_state, nrealizations, nstep):\n",
    "    # Simulate the realizations\n",
    "    chain = MarkovChain(transition_matrix=transition_matrix, states=states)\n",
    "    arr = np.zeros(((nstep+1), nrealizations))\n",
    "    \n",
    "    for r in range(nrealizations):\n",
    "        simulation = chain.generate_states(current_state=initial_state, no=(nstep+1))\n",
    "        arr[:, r] = np.array(simulation)\n",
    "        \n",
    "    # Count the occurence of each state at time nstep\n",
    "    nstates = len(states) #number of states\n",
    "    count = np.zeros(nstates)\n",
    "    \n",
    "    for i in range(nstates):\n",
    "        state = int(states[i])\n",
    "        index = np.where(arr[nstep] == state)\n",
    "        count[i] = len(index[0])\n",
    "        \n",
    "    # Compute the empirical distribution by normalizing by the total number of samples\n",
    "    distribution = count/nrealizations\n",
    "        \n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example showing how to use this function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_distribution = get_empirical_dist(states=['0', '1'], \n",
    "                         transition_matrix=[[0.5, 0.5], [0.5,  0.5]], \n",
    "                         initial_state='0', \n",
    "                         nrealizations=100, \n",
    "                         nstep=10)\n",
    "\n",
    "print(empirical_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot this distribution as a simple histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "bar_positions = np.arange(len(empirical_distribution))\n",
    "ax.bar(bar_positions, empirical_distribution)\n",
    "plt.xticks(bar_positions, ('0', '1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework 1 (see problem 2 question 4)\n",
    "\n",
    "Replace \"X\"'s with the correct values in the cell below (you can either use a screenshot of the notebook to write your answer, or handwrite the content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empirical_distribution = get_empirical_dist(states=X, \n",
    "                         transition_matrix=X, \n",
    "                         initial_state=X, \n",
    "                         nrealizations=100, \n",
    "                         nstep=10)\n",
    "\n",
    "print(empirical_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
